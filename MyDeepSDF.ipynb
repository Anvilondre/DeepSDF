{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a6a64fd",
   "metadata": {},
   "source": [
    "## This is my take on DeepSDF\n",
    "\n",
    "To be completely honest, I'm not sure if that's what I was supposed to do. Maybe simple geometric solution would work, but here we go :)\n",
    "\n",
    "That's basically my implementation of [DeepSDF](https://github.com/facebookresearch/DeepSDF/).\n",
    "\n",
    "To give them credits, I looked at their implementation, while doing mine (not that it was very helpful though). So I'd recommend diving into their repo for a more sophisticated approach.\n",
    "\n",
    "### P.S.\n",
    "Take this project with a grain of salt, since for real-world applications it would be much more feasible to get a pretrained DeepSDF (for example from [here](https://github.com/marian42/shapegan/tree/pretrained-deepsdf-shapenet/examples/deepsdf-shapenet-pretrained)) and produce much better scores. This notebook is specifically about my experience in discovering the mesh & SDF kind-of data and working with shape embeddings, aka DeepSDF.\n",
    "\n",
    "## Data\n",
    "You can download the prepared data [here](https://drive.google.com/drive/folders/1AE_mohNpxRg3JXoBX2oiN-8xaMcGYYuX?usp=sharing)\n",
    "\n",
    "## TL;DR\n",
    "\n",
    "### What I got\n",
    "\n",
    "- Modeled and trained a DeepSDF model \n",
    "- 8 * float64 = 64 byte representations\n",
    "- 4.6 ms for a batch size of 1024\n",
    "- Around 0.94 validation f1 occupancy with sdf < 1e-3 (very dirty considering the sign distribution though)\n",
    "- Pretty bad inside-shape modeling\n",
    "\n",
    "### What could help and improve my results\n",
    "- **More flexible and accurate solver and better data sampling for inside-points modeling (maybe sampling negative SDFs more agressively)**\n",
    "- **More RAM and time for modeling a much bigger dataset (30 train models doesn't sound like a good amount of information for learning the latent shape space)**\n",
    "- **Adequate validation (I believe all the hard stuff is done in this notebook, and it shouldn't be difficult to push the f1 score up from this point, it's just a routine work with data)**\n",
    "- Doing the loss clamping (as proposed in the original paper) for a better surface and occupancy modeling\n",
    "- More experiments with an architecture and training (weight decay as proposed in DeepSDF, lr scheduling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d9f2600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import trimesh\n",
    "import numpy as np\n",
    "\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from mesh_to_sdf import sample_sdf_near_surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ec488e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsampling the train and test data, since my PC isn't from NASA\n",
    "SUBSAMPLE_TRAIN_VALID = 30\n",
    "SUBSAMPLE_TEST = 5\n",
    "\n",
    "# Network params\n",
    "NUM_EPOCHS_TRAIN = 50\n",
    "NUM_EPOCHS_TEST = 30\n",
    "\n",
    "BATCH_SIZE = 1024\n",
    "EMBEDDING_DIM = 8  # Higher values neither help nor make sence considering the amount of subsampled shapes\n",
    "DROPOUT = 0.2\n",
    "HIDDEN_DIMS = [64] * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "043ddae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleBlock(nn.Module):\n",
    "\n",
    "    ''' Linear -> BN -> Dropout -> LeakyReLU '''\n",
    "    \n",
    "    def __init__(self, inp_dim, out_dim, dropout=0.2):\n",
    "        super(SimpleBlock, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(inp_dim, out_dim),\n",
    "            nn.BatchNorm1d(out_dim),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.model(X)\n",
    "    \n",
    "class SDFDecoder(nn.Module):\n",
    "    \n",
    "    ''' MLP decoder of SimpleBlock layers with tahn activation in prediction head '''\n",
    "    \n",
    "    def __init__(self, inp_dim, hidden_dims):\n",
    "        super(SDFDecoder, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            SimpleBlock(inp_dim, hidden_dims[0]),\n",
    "            *[SimpleBlock(i, o) for i, o in zip(hidden_dims, hidden_dims[1:])],\n",
    "            nn.Linear(hidden_dims[-1], 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.model(X)\n",
    "    \n",
    "    \n",
    "class SDFDataset(Dataset):\n",
    "    \n",
    "    ''' Dataset class for producing [latent_vector + xyz] -> SDF mapping'''\n",
    "    \n",
    "    def __init__(self, filenames, n_samples, encoder):\n",
    "        \"\"\" Supports loading and sampling from @filenames paths but I didn't use it in the end \"\"\"\n",
    "        self.encoder = encoder\n",
    "        self.indices = []\n",
    "        self.X = torch.Tensor([])\n",
    "        self.y = torch.Tensor([])\n",
    "        \n",
    "        for i, filepath in enumerate(tqdm(filenames)):\n",
    "            self.indices.extend(n_samples * [i])\n",
    "            mesh = trimesh.load(filepath)\n",
    "            points, sdf = sample_sdf_near_surface(mesh, number_of_points=n_samples, sign_method='depth')\n",
    "            self.X = torch.cat((self.X, torch.from_numpy(points)))\n",
    "            self.y = torch.cat((self.y, torch.from_numpy(sdf)))\n",
    "        \n",
    "        self.indices = torch.Tensor(self.indices).int()\n",
    "        \n",
    "    # A bit tinky-winky save/load, zipping would make more sense but whatever\n",
    "    def save(self, indices_name, X_name, y_name):\n",
    "        torch.save(self.indices, indices_name)\n",
    "        torch.save(self.X, X_name)\n",
    "        torch.save(self.y, y_name)\n",
    "    \n",
    "    def load(self, indices_name, X_name, y_name):\n",
    "        self.indices = torch.load(indices_name)\n",
    "        self.X = torch.load(X_name)\n",
    "        self.y = torch.load(y_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\" Get encoded latent vector + xyz pair with corresponding SDF \"\"\"\n",
    "        return torch.cat((self.encoder(self.indices[idx]), self.X[idx])), self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f65e2e2c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encoders initialization\n",
    "train_encoder = nn.Embedding(SUBSAMPLE_TRAIN_VALID, EMBEDDING_DIM)\n",
    "test_encoder = nn.Embedding(SUBSAMPLE_TEST, EMBEDDING_DIM)\n",
    "\n",
    "# We'll load the prepaired data in the next cell\n",
    "train_dataset = SDFDataset([], None, train_encoder)\n",
    "valid_dataset = SDFDataset([], None, train_encoder)\n",
    "test_dataset = SDFDataset([], None, test_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6f0632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load already processed data\n",
    "train_dataset.load('processed_data/train_idx.pt', 'processed_data/train_X.pt', 'processed_data/train_y.pt')\n",
    "valid_dataset.load('processed_data/valid_idx.pt', 'processed_data/valid_X.pt', 'processed_data/valid_y.pt')\n",
    "test_dataset.load('processed_data/test_idx.pt', 'processed_data/test_X.pt', 'processed_data/test_y.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db43224f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, a bit tinky-winky subsampling\n",
    "train_ind = train_dataset.indices < SUBSAMPLE_TRAIN_VALID\n",
    "valid_ind = valid_dataset.indices < SUBSAMPLE_TRAIN_VALID\n",
    "test_ind = test_dataset.indices < SUBSAMPLE_TEST\n",
    "\n",
    "train_dataset.indices = train_dataset.indices[train_ind]\n",
    "train_dataset.X = train_dataset.X[train_ind]\n",
    "train_dataset.y = train_dataset.y[train_ind]\n",
    "\n",
    "valid_dataset.indices = valid_dataset.indices[valid_ind]\n",
    "valid_dataset.X = valid_dataset.X[valid_ind]\n",
    "valid_dataset.y = valid_dataset.y[valid_ind]\n",
    "\n",
    "test_dataset.indices = test_dataset.indices[test_ind]\n",
    "test_dataset.X = test_dataset.X[test_ind]\n",
    "test_dataset.y = test_dataset.y[test_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5408ec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dea008e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_dataset)=3000000\n",
      "len(valid_dataset)=600000\n",
      "len(test_dataset)=400000\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(train_dataset)=}', f'{len(valid_dataset)=}', f'{len(test_dataset)=}', sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3049a261",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = SDFDecoder(EMBEDDING_DIM + 3, HIDDEN_DIMS)\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(chain(train_encoder.parameters(), decoder.parameters()), lr = 0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc5603af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.04344232380390167, f1: 0.8998435054773084: 100%|█| 2930/2930 [01:39<00:00, 29.47it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=0, loss=0.0395, f1=0.898,     occupancy_f1=0.946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.04686539247632027, f1: 0.9051321928460342: 100%|█| 2930/2930 [01:26<00:00, 33.68it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=1, loss=0.0396, f1=0.898,     occupancy_f1=0.946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.013404348865151405, f1: 0.9000000000000001: 100%|█| 2930/2930 [01:29<00:00, 32.62it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=2, loss=0.0137, f1=0.897,     occupancy_f1=0.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.009753807447850704, f1: 0.8982785602503912: 100%|█| 2930/2930 [01:28<00:00, 33.24it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=3, loss=0.0103, f1=0.897,     occupancy_f1=0.945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.008623799309134483, f1: 0.9017160686427457: 100%|█| 2930/2930 [01:35<00:00, 30.80it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=4, loss=0.0092, f1=0.894,     occupancy_f1=0.941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.009868474677205086, f1: 0.8885375494071146: 100%|█| 2930/2930 [01:37<00:00, 30.13it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=5, loss=0.0086, f1=0.892,     occupancy_f1=0.940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.007716733496636152, f1: 0.8957345971563981: 100%|█| 2930/2930 [01:31<00:00, 31.91it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=6, loss=0.0083, f1=0.892,     occupancy_f1=0.938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.00811475794762373, f1: 0.8833865814696484: 100%|█| 2930/2930 [01:32<00:00, 31.72it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=7, loss=0.0081, f1=0.877,     occupancy_f1=0.918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.00865777675062418, f1: 0.8885350318471338: 100%|█| 2930/2930 [01:32<00:00, 31.71it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=8, loss=0.0078, f1=0.888,     occupancy_f1=0.933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.006950098555535078, f1: 0.88659793814433: 100%|█| 2930/2930 [01:32<00:00, 31.53it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=9, loss=0.0076, f1=0.895,     occupancy_f1=0.942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.009306528605520725, f1: 0.8908227848101266: 100%|█| 2930/2930 [01:29<00:00, 32.57it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=10, loss=0.0076, f1=0.892,     occupancy_f1=0.938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.00768881244584918, f1: 0.8892430278884463: 100%|█| 2930/2930 [01:30<00:00, 32.37it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=11, loss=0.0074, f1=0.889,     occupancy_f1=0.934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.006368952803313732, f1: 0.8848292295472596: 100%|█| 2930/2930 [01:32<00:00, 31.80it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=12, loss=0.0074, f1=0.847,     occupancy_f1=0.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.008971486240625381, f1: 0.8966061562746647: 100%|█| 2930/2930 [01:37<00:00, 30.17it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=13, loss=0.0073, f1=0.890,     occupancy_f1=0.936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.007169054355472326, f1: 0.8981191222570534: 100%|█| 2930/2930 [01:31<00:00, 31.94it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=14, loss=0.0077, f1=0.884,     occupancy_f1=0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.006643187720328569, f1: 0.9099378881987578: 100%|█| 2930/2930 [01:35<00:00, 30.71it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=15, loss=0.0072, f1=0.887,     occupancy_f1=0.932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.006735484581440687, f1: 0.8798076923076924: 100%|█| 2930/2930 [01:32<00:00, 31.84it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=16, loss=0.0072, f1=0.887,     occupancy_f1=0.931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.008244123309850693, f1: 0.8954041204437401: 100%|█| 2930/2930 [01:32<00:00, 31.74it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=17, loss=0.0072, f1=0.886,     occupancy_f1=0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.0086289057508111, f1: 0.8849840255591054: 100%|█| 2930/2930 [01:41<00:00, 28.86it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=18, loss=0.0071, f1=0.889,     occupancy_f1=0.934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.006356589961796999, f1: 0.8846459824980112: 100%|█| 2930/2930 [01:33<00:00, 31.28it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=19, loss=0.0071, f1=0.885,     occupancy_f1=0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.006907808594405651, f1: 0.9043887147335423: 100%|█| 2930/2930 [01:33<00:00, 31.50it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=20, loss=0.0070, f1=0.893,     occupancy_f1=0.939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.006666330620646477, f1: 0.8842443729903536: 100%|█| 2930/2930 [01:33<00:00, 31.48it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=21, loss=0.0070, f1=0.894,     occupancy_f1=0.940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.005677207838743925, f1: 0.9041309431021044: 100%|█| 2930/2930 [01:36<00:00, 30.51it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=22, loss=0.0070, f1=0.892,     occupancy_f1=0.938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.007726510986685753, f1: 0.8894192521877485: 100%|█| 2930/2930 [01:33<00:00, 31.35it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=23, loss=0.0070, f1=0.892,     occupancy_f1=0.939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.00893603265285492, f1: 0.8801287208366856: 100%|█| 2930/2930 [01:32<00:00, 31.70it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=24, loss=0.0070, f1=0.884,     occupancy_f1=0.928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.008289656601846218, f1: 0.9106449106449106: 100%|█| 2930/2930 [01:41<00:00, 28.99it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=25, loss=0.0070, f1=0.889,     occupancy_f1=0.935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.0057388306595385075, f1: 0.903831118060985: 100%|█| 2930/2930 [01:32<00:00, 31.60it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=26, loss=0.0069, f1=0.885,     occupancy_f1=0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.0069833677262067795, f1: 0.8904761904761904: 100%|█| 2930/2930 [01:34<00:00, 30.97i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=27, loss=0.0069, f1=0.881,     occupancy_f1=0.924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.007301142904907465, f1: 0.8929421094369547: 100%|█| 2930/2930 [01:32<00:00, 31.61it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=28, loss=0.0069, f1=0.881,     occupancy_f1=0.924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.008149604313075542, f1: 0.8913560666137985: 100%|█| 2930/2930 [01:34<00:00, 30.89it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=29, loss=0.0068, f1=0.890,     occupancy_f1=0.935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.007708899211138487, f1: 0.8724939855653568: 100%|█| 2930/2930 [01:33<00:00, 31.31it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=30, loss=0.0068, f1=0.889,     occupancy_f1=0.934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.006839623674750328, f1: 0.8998435054773083: 100%|█| 2930/2930 [01:40<00:00, 29.18it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=31, loss=0.0068, f1=0.893,     occupancy_f1=0.939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.006167256738990545, f1: 0.877502001601281: 100%|█| 2930/2930 [01:34<00:00, 31.00it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=32, loss=0.0067, f1=0.885,     occupancy_f1=0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.005818095523864031, f1: 0.8878281622911695: 100%|█| 2930/2930 [01:35<00:00, 30.72it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=33, loss=0.0067, f1=0.883,     occupancy_f1=0.926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.008353653363883495, f1: 0.8509575353871773: 100%|█| 2930/2930 [01:36<00:00, 30.38it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=34, loss=0.0068, f1=0.881,     occupancy_f1=0.923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.006025611888617277, f1: 0.8798076923076923: 100%|█| 2930/2930 [01:37<00:00, 30.16it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=35, loss=0.0067, f1=0.893,     occupancy_f1=0.939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.0064497594721615314, f1: 0.8974158183241974: 100%|█| 2930/2930 [01:34<00:00, 31.11i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=36, loss=0.0067, f1=0.895,     occupancy_f1=0.942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.006586477626115084, f1: 0.8908227848101267: 100%|█| 2930/2930 [01:35<00:00, 30.75it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=37, loss=0.0067, f1=0.886,     occupancy_f1=0.931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.005862246733158827, f1: 0.8913385826771653: 100%|█| 2930/2930 [01:34<00:00, 31.10it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=38, loss=0.0067, f1=0.893,     occupancy_f1=0.940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.005514708813279867, f1: 0.8839427662957074: 100%|█| 2930/2930 [01:35<00:00, 30.71it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=39, loss=0.0071, f1=0.887,     occupancy_f1=0.930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.005446005146950483, f1: 0.8915281076801267: 100%|█| 2930/2930 [01:34<00:00, 31.12it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=40, loss=0.0066, f1=0.891,     occupancy_f1=0.938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.005131710786372423, f1: 0.9007036747458951: 100%|█| 2930/2930 [01:33<00:00, 31.25it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=41, loss=0.0066, f1=0.895,     occupancy_f1=0.942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.006648695562034845, f1: 0.886762360446571: 100%|█| 2930/2930 [01:33<00:00, 31.23it/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=42, loss=0.0066, f1=0.874,     occupancy_f1=0.914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.005919893272221088, f1: 0.9024199843871976: 100%|█| 2930/2930 [01:34<00:00, 31.16it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=43, loss=0.0066, f1=0.890,     occupancy_f1=0.935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.006516121793538332, f1: 0.8986645718774549: 100%|█| 2930/2930 [01:35<00:00, 30.82it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=44, loss=0.0067, f1=0.889,     occupancy_f1=0.934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.007771013770252466, f1: 0.8881839809674861: 100%|█| 2930/2930 [01:37<00:00, 29.99it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=45, loss=0.0066, f1=0.885,     occupancy_f1=0.929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.006158776115626097, f1: 0.8990536277602522: 100%|█| 2930/2930 [01:35<00:00, 30.84it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=46, loss=0.0066, f1=0.891,     occupancy_f1=0.937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.007832656614482403, f1: 0.8894192521877484: 100%|█| 2930/2930 [01:39<00:00, 29.35it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=47, loss=0.0066, f1=0.887,     occupancy_f1=0.932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.005524642299860716, f1: 0.8930817610062893: 100%|█| 2930/2930 [01:34<00:00, 30.86it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=48, loss=0.0066, f1=0.894,     occupancy_f1=0.941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.006987675558775663, f1: 0.8937844217151848: 100%|█| 2930/2930 [01:36<00:00, 30.36it\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid epoch=49, loss=0.0065, f1=0.891,     occupancy_f1=0.937\n"
     ]
    }
   ],
   "source": [
    "train_encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS_TRAIN):\n",
    "    pbar = tqdm(train_dataloader)\n",
    "    for X, y in pbar:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = decoder(X).squeeze()\n",
    "    \n",
    "        loss = criterion(out, y)\n",
    "        pbar.set_description(f'Batch loss: {loss.item()}, f1: {f1_score(y>0, out>0)}', refresh=True)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    valid_y, valid_out = map(torch.cat, zip(*[(y, decoder(X).squeeze()) for X, y in valid_dataloader]))\n",
    "    \n",
    "    ind = valid_y.abs() < 1e-3\n",
    "    occupancy_y = valid_y[ind] > 0\n",
    "    occupancy_out = valid_out[ind] > 0\n",
    "\n",
    "    print(f'Valid {epoch=}, loss={criterion(valid_out, valid_y).item():.4f}, f1={f1_score(valid_y>0, valid_out>0):.3f},\\\n",
    "     occupancy_f1={f1_score(occupancy_y, occupancy_out):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7db8cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, I don't have a NASA PC\n",
    "del train_dataset, valid_dataset, train_dataloader, valid_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "059e71ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the decoder layers to finetune the test representations\n",
    "decoder.requires_grad = False\n",
    "for param in decoder.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62abf5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_criterion = nn.L1Loss()\n",
    "test_optimizer = torch.optim.Adam(test_encoder.parameters(), lr = 0.0003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c046d847",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.06008940190076828, f1: 0.6603550295857987: 100%|█| 391/391 [00:12<00:00, 32.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch=0, loss=0.1445, f1=0.457,    occupancy_f1=0.319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.11212427914142609, f1: 0.4747191011235955: 100%|█| 391/391 [00:11<00:00, 33.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch=1, loss=0.0856, f1=0.568,    occupancy_f1=0.437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.026577701792120934, f1: 0.8295454545454546: 100%|█| 391/391 [00:11<00:00, 32.85it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch=2, loss=0.0548, f1=0.685,    occupancy_f1=0.549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.04530294984579086, f1: 0.7005524861878454: 100%|█| 391/391 [00:11<00:00, 34.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch=3, loss=0.0409, f1=0.754,    occupancy_f1=0.606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.14327748119831085, f1: 0.5142083897158322: 100%|█| 391/391 [00:11<00:00, 32.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch=4, loss=0.0322, f1=0.805,    occupancy_f1=0.648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.034217238426208496, f1: 0.7749003984063745: 100%|█| 391/391 [00:11<00:00, 33.60it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch=5, loss=0.0282, f1=0.828,    occupancy_f1=0.665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.02553776279091835, f1: 0.8506375227686702: 100%|█| 391/391 [00:11<00:00, 33.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch=6, loss=0.0254, f1=0.846,    occupancy_f1=0.680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.02668728493154049, f1: 0.823199251637044: 100%|██| 391/391 [00:11<00:00, 33.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch=7, loss=0.0235, f1=0.861,    occupancy_f1=0.690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.02032265067100525, f1: 0.895104895104895: 100%|██| 391/391 [00:11<00:00, 33.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch=8, loss=0.0218, f1=0.872,    occupancy_f1=0.698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.02156975492835045, f1: 0.8855895196506549: 100%|█| 391/391 [00:11<00:00, 34.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch=9, loss=0.0207, f1=0.877,    occupancy_f1=0.702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.017775217071175575, f1: 0.8875326939843068: 100%|█| 391/391 [00:11<00:00, 32.65it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch=10, loss=0.0202, f1=0.879,    occupancy_f1=0.703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.017910804599523544, f1: 0.8818897637795275: 100%|█| 391/391 [00:11<00:00, 33.37it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch=11, loss=0.0193, f1=0.883,    occupancy_f1=0.706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.016597749665379524, f1: 0.8900523560209425: 100%|█| 391/391 [00:11<00:00, 34.04it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch=12, loss=0.0186, f1=0.884,    occupancy_f1=0.707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.01919686608016491, f1: 0.8645276292335117: 100%|█| 391/391 [00:11<00:00, 32.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch=13, loss=0.0178, f1=0.887,    occupancy_f1=0.709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.014323596842586994, f1: 0.8939526730937775: 100%|█| 391/391 [00:11<00:00, 33.21it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch=14, loss=0.0172, f1=0.886,    occupancy_f1=0.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.014604304917156696, f1: 0.8814749780509219: 100%|█| 391/391 [00:11<00:00, 33.31it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch=15, loss=0.0164, f1=0.888,    occupancy_f1=0.710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.013365899212658405, f1: 0.8969696969696969: 100%|█| 391/391 [00:11<00:00, 33.68it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch=16, loss=0.0157, f1=0.888,    occupancy_f1=0.710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.017211416736245155, f1: 0.8477666362807658: 100%|█| 391/391 [00:11<00:00, 32.77it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch=17, loss=0.0148, f1=0.889,    occupancy_f1=0.710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.01550893485546112, f1: 0.8695652173913043: 100%|█| 391/391 [00:12<00:00, 32.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch=18, loss=0.0140, f1=0.889,    occupancy_f1=0.711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.010101839900016785, f1: 0.893913043478261: 100%|█| 391/391 [00:11<00:00, 33.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch=19, loss=0.0133, f1=0.888,    occupancy_f1=0.710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.010683066211640835, f1: 0.8944636678200691: 100%|█| 391/391 [00:14<00:00, 27.81it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch=20, loss=0.0127, f1=0.888,    occupancy_f1=0.710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.013909241184592247, f1: 0.9090909090909091: 100%|█| 391/391 [00:11<00:00, 34.13it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch=21, loss=0.0123, f1=0.888,    occupancy_f1=0.709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.010546230711042881, f1: 0.9017241379310346: 100%|█| 391/391 [00:11<00:00, 33.16it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch=22, loss=0.0120, f1=0.889,    occupancy_f1=0.710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.01228383369743824, f1: 0.8873362445414846: 100%|█| 391/391 [00:11<00:00, 33.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch=23, loss=0.0117, f1=0.888,    occupancy_f1=0.709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.011690007522702217, f1: 0.8894691035683202: 100%|█| 391/391 [00:11<00:00, 34.10it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch=24, loss=0.0115, f1=0.888,    occupancy_f1=0.710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.009921910241246223, f1: 0.8740088105726873: 100%|█| 391/391 [00:12<00:00, 32.38it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch=25, loss=0.0112, f1=0.888,    occupancy_f1=0.710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.01305618416517973, f1: 0.8747795414462082: 100%|█| 391/391 [00:12<00:00, 32.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch=26, loss=0.0111, f1=0.888,    occupancy_f1=0.710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.013755199499428272, f1: 0.8869412795793163: 100%|█| 391/391 [00:12<00:00, 32.44it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch=27, loss=0.0110, f1=0.888,    occupancy_f1=0.710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.008971111848950386, f1: 0.8737864077669903: 100%|█| 391/391 [00:11<00:00, 32.81it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch=28, loss=0.0108, f1=0.888,    occupancy_f1=0.710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch loss: 0.009782833978533745, f1: 0.8990509059534081: 100%|█| 391/391 [00:11<00:00, 33.92it/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch=29, loss=0.0107, f1=0.888,    occupancy_f1=0.710\n"
     ]
    }
   ],
   "source": [
    "test_encoder.train()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS_TEST):\n",
    "    pbar = tqdm(test_dataloader)\n",
    "    for X, y in pbar:\n",
    "        \n",
    "        test_optimizer.zero_grad()\n",
    "        \n",
    "        out = decoder(X).squeeze()\n",
    "        \n",
    "        test_loss = test_criterion(out, y)\n",
    "        pbar.set_description(f'Batch loss: {test_loss.item()}, f1: {f1_score(y>0, out>0)}', refresh=True)\n",
    "\n",
    "        # Backward pass\n",
    "        test_loss.backward()\n",
    "        test_optimizer.step()\n",
    "    \n",
    "    test_y, test_out = map(torch.cat, zip(*[(y, decoder(X).squeeze()) for X, y in test_dataloader]))\n",
    "    ind = test_y < 1e-3\n",
    "    occupancy_y = test_y[ind] > 0\n",
    "    occupancy_out = test_out[ind] > 0\n",
    "\n",
    "    print(f'Test {epoch=}, loss={criterion(test_out, test_y).item():.4f}, f1={f1_score(test_y>0, test_out>0):.3f},\\\n",
    "    occupancy_f1={f1_score(occupancy_y, occupancy_out):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8915b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171612, 171612)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(occupancy_y), len(occupancy_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "384ff1c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(95473), tensor(167854))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occupancy_y.sum(), occupancy_out.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b12bc8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(test_dataloader))[0]\n",
    "len(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "083436d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.63 ms ± 1.72 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit decoder(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db485290",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
